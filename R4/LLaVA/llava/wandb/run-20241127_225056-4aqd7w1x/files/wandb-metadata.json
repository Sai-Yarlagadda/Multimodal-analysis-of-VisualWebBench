{
  "os": "Linux-5.15.0-107-generic-x86_64-with-glibc2.31",
  "python": "3.10.15",
  "startedAt": "2024-11-28T03:50:56.486402Z",
  "args": [
    "--local_rank=0",
    "--lora_enable",
    "True",
    "--lora_r",
    "128",
    "--lora_alpha",
    "256",
    "--mm_projector_lr",
    "2e-5",
    "--deepspeed",
    "/home/abadagab/LLaVA/scripts/zero3.json",
    "--model_name_or_path",
    "liuhaotian/llava-v1.5-7b",
    "--version",
    "v1",
    "--data_path",
    "dataset.json",
    "--image_folder",
    "/home/abadagab/LLaVA/llava",
    "--vision_tower",
    "openai/clip-vit-large-patch14-336",
    "--mm_projector_type",
    "mlp2x_gelu",
    "--mm_vision_select_layer",
    "-2",
    "--mm_use_im_start_end",
    "False",
    "--mm_use_im_patch_token",
    "False",
    "--image_aspect_ratio",
    "pad",
    "--group_by_modality_length",
    "True",
    "--bf16",
    "True",
    "--output_dir",
    "./checkpoints/llava-v1.5-7b-task-lora",
    "--num_train_epochs",
    "10",
    "--per_device_train_batch_size",
    "16",
    "--per_device_eval_batch_size",
    "4",
    "--gradient_accumulation_steps",
    "1",
    "--evaluation_strategy",
    "no",
    "--save_strategy",
    "steps",
    "--save_steps",
    "50000",
    "--save_total_limit",
    "1",
    "--learning_rate",
    "2e-4",
    "--weight_decay",
    "0.",
    "--warmup_ratio",
    "0.03",
    "--lr_scheduler_type",
    "cosine",
    "--logging_steps",
    "1",
    "--tf32",
    "True",
    "--model_max_length",
    "2048",
    "--gradient_checkpointing",
    "True",
    "--dataloader_num_workers",
    "4",
    "--lazy_preprocess",
    "True",
    "--report_to",
    "wandb"
  ],
  "program": "/home/abadagab/LLaVA/llava/train/train_mem.py",
  "codePath": "llava/train/train_mem.py",
  "git": {
    "remote": "https://github.com/haotian-liu/LLaVA.git",
    "commit": "c121f0432da27facab705978f83c4ada465e46fd"
  },
  "email": "abadagab@andrew.cmu.edu",
  "root": "/home/abadagab/LLaVA/llava",
  "host": "lambda-a6000",
  "username": "abadagab",
  "executable": "/home/abadagab/anaconda3/envs/llava/bin/python",
  "codePathLocal": "train/train_mem.py",
  "cpu_count": 10,
  "cpu_count_logical": 20,
  "gpu": "NVIDIA RTX A6000",
  "gpu_count": 2,
  "disk": {
    "/": {
      "total": "3936290357248",
      "used": "3727793745920"
    }
  },
  "memory": {
    "total": "134734422016"
  },
  "cpu": {
    "count": 10,
    "countLogical": 20
  },
  "gpu_nvidia": [
    {
      "name": "NVIDIA RTX A6000",
      "memoryTotal": "51527024640",
      "cudaCores": 10752,
      "architecture": "Ampere"
    },
    {
      "name": "NVIDIA RTX A6000",
      "memoryTotal": "51527024640",
      "cudaCores": 10752,
      "architecture": "Ampere"
    }
  ],
  "cudaVersion": "12.4"
}